{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Workshop Part 3\n",
    "Google Collab Link:\n",
    "https://colab.research.google.com/drive/1zf55WftULwMF1Wg6qSH2nIva-ilXdX-l\n",
    "\n",
    "## 3.0 Overview\n",
    "**4 Steps to train your model in Keras**\n",
    "1. Get your data into an easy format.\n",
    "2. Define your model\n",
    "```python\n",
    "    from keras.models import Sequential\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "    #...\n",
    "```\n",
    "3. Compile the model (allocate memory, set up losses and metrics)\n",
    "```python\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, # for classification\n",
    "                  optimizer=keras.optimizers.SGD(),\n",
    "                  metrics=['accuracy'])\n",
    "```\n",
    "    * this does NOT start the training yet\n",
    "4. fit the model\n",
    "```python\n",
    "    model.fit(x_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from models import build_and_compile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Watching - Get your data\n",
    "* we are again using MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are doing some stuff in the background to not confuse you too much\n",
    "from data_loader import setup_data\n",
    "\n",
    "x_train, y_train, x_test, y_test, input_shape, num_classes = setup_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember Softmax? \n",
    "\n",
    "Our Targets are only the class as a single number.\n",
    "But we want to have a **vector** for each class that as a **1** at the position of the correct class\n",
    "\n",
    "For example:\n",
    "the correct class is **4**: and we have 10 classes\n",
    "we want to have\n",
    "[0, 0, 0, **1**, 0, ...]\n",
    "\n",
    "We can do this easily with \n",
    "```python\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "```\n",
    "and also for ```y_test```\n",
    "\n",
    "This kind of format for classification is called **one-hot**-encoding or categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "if not y_train.shape[-1] == 10: # the if is just so that you can run this multiple times without breaking it\n",
    "    print('target shape before: {}'.format(y_train.shape))\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    print('target shape after: {}'.format(y_train.shape))\n",
    "else:\n",
    "    print('target shape: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 HandsOn - Build your model\n",
    "* Keras supports ```Sequential()````model definition. You start with the inputs and end with the outputs\n",
    "* you start with an empty model\n",
    "```python\n",
    "    model = Sequential()\n",
    "```\n",
    "* then you just **add** Layers\n",
    "```python\n",
    "    model.add(layer)\n",
    "```\n",
    "* some example Layers\n",
    "```python\n",
    "    # creates a 2D conv layer with 32 feature maps, 3x3 convolutions, and relu activation\n",
    "    conv_layer = Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 activation='relu')\n",
    "    # a Dense layer is the same as a fully connected layer\n",
    "    fc_layer = Dense(128, activation='relu')\n",
    "    pooling_layer = MaxPooling2D(pool_size=(2, 2))\n",
    "```\n",
    "* all Keras Layers\n",
    "   https://keras.io/layers/about-keras-layers/\n",
    "   \n",
    "   \n",
    "## your assigment: create the following model\n",
    "```\n",
    "2D conv - 3x3 - 32 feature maps - stride 1 - relu\n",
    "2D conv - 3x3 - 64 feature maps - stride 1 - relu\n",
    "2D max pooling - stride - stride 2\n",
    "FC layer - 128 feature maps - relu\n",
    "AND a final FC layer (fill in the gaps)\n",
    "FC layer - ?? feature maps - ?? activation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "model = Sequential()\n",
    "# continue ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking your code: visualize your model when you are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "model.summary()\n",
    "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True) # similar output\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 HandsOn - Compile your Model\n",
    "```python\n",
    "    model.compile(loss=,\n",
    "                  optimizer=,\n",
    "                  metrics=[])\n",
    "```\n",
    "\n",
    "* choose a suitable loss\n",
    "https://keras.io/losses/\n",
    "* choose an informative metric. ```metrics``` has to be a list\n",
    "https://keras.io/metrics/\n",
    "* choose ADAM for optimization\n",
    "```python\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "model.compile(loss=,\n",
    "              optimizer=,\n",
    "              metrics=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 HandsOn - Fit your Model\n",
    "\n",
    "* use\n",
    "```python\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=12,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "```\n",
    "* experiment with different batch sizes.\n",
    "* think about what else would be useful during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Watching: saving checkpoints of your model during training\n",
    "\n",
    "* you want to have the weights of your model in the end\n",
    "* you want to have the best model, before overfitting starts\n",
    "* this can be done very easily with model callbacks\n",
    "https://keras.io/callbacks/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = #\n",
    "current_weights = #\n",
    "\n",
    "\n",
    "def list_weights(epoch, logs): # arguments have to be like this according to https://keras.io/callbacks/\n",
    "    print(glob.glob('*.hdf5'))\n",
    "list_dir_cb = keras.callbacks.LambdaCallback(on_epoch_begin=list_weights)\n",
    "\n",
    "callbacks = [best_weights, current_weights, list_dir_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_and_compile(input_shape, num_classes) # reinitialize untrained model\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "small_x_train = x_train[:1000]\n",
    "small_y_train = y_train[:1000]\n",
    "\n",
    "model.fit(small_x_train, small_y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks, # <<--- new part\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Watching: Live Loss Plotting during Training\n",
    "\n",
    "Thanks god someone made a package for that already\n",
    "https://github.com/stared/livelossplot\n",
    "\n",
    "* more advanced visualization --> Tensorboard\n",
    "* Tensorboard might not work on google collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKeras\n",
    "callbacks = [best_weights, # from before\n",
    "             current_weights, # from before\n",
    "             PlotLossesKeras(), # <<-- new callback\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 12\n",
    "model = build_and_compile(input_shape, num_classes)# reinitialize untrained model\n",
    "model.fit(small_x_train, small_y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! \n",
    "you now know most of the tools to get going with your models.\n",
    "\n",
    "Please remember to give us feedback at the very end\n",
    "https://docs.google.com/forms/d/e/1FAIpQLSfOrciwCGaXOsYn0U86yfu9SHwau-9YAfkzKaGN7OP6-OGjKQ/viewform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_ws]",
   "language": "python",
   "name": "conda-env-dl_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
