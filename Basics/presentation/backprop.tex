\documentclass{beamer}

\usepackage{tikz}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage{amsthm}
\usepackage{graphicx}
\newtheorem{mydef}{Definition}

\usepackage[citestyle=alphabetic,bibstyle=numeric,hyperref,backend=biber]{biblatex}
\addbibresource{backprop.bib}
\bibhang1em

\title{Backpropagation}
\author{Leander Kurscheidt}
\institute{Hack \& S{\"o}hne}
\date{2018}
     

\begin{document}
 
\frame{\titlepage}
 
\begin{frame}
\frametitle{Backpropagation}
\begin{itemize}
    \item We've got the forward propagation, but how to train the neural network?
    \item many approaches, but Backward-Propagation is enabling the whole Deep-Learning Hype
\end{itemize}
for BP to work, \textbf{everything} needs to be differentiable!!!!
\end{frame}

\begin{frame}{Intuition: Learning as an Optimization-Problem}
in theory, it's easy!
\vfill
\begin{enumerate}
    \item assign every instance of neural network a score through a differentiable function (error function), e.g. derivation from target
    \item optimize the score
\end{enumerate}
\end{frame}

\begin{frame}{Intuition: Learning as an Optimization-Problem}
\begin{figure}
\includegraphics[scale=0.5]{../assets/512px-Extrema_example_original.png}
\caption{\cite{extremaMinima}}
\end{figure}
\end{frame}

\begin{frame}{Intuition: Learning as an Optimization-Problem}
    common vocabulary:
    \vfill
    \begin{enumerate}
        \item a \textbf{Loss-Function} $L$ is something I want to minimize
        \item an \textbf{Error-Function} $E : Output_{NN} \bigtimes Target \rightarrow \mathbb{R} $ \\
        $\Rightarrow$ in our context: Loss-Function = Error-Function
    \end{enumerate}
\end{frame}

\begin{frame}{Intuition: Learning as an Optimization-Problem}
    \begin{figure}
    \includegraphics[width=\textwidth]{../assets/noshort.png}
    \caption{\cite{DBLP:journals/corr/abs-1712-09913}}
    \end{figure}
\end{frame}

\begin{frame}{The BP-Algorithm}
    \vfill
    \centering
    \begin{beamercolorbox}[sep=8pt,center,shadow=true,rounded=true]{title}
      \usebeamerfont{title}essentially: nothing more than the chain rule!
    \end{beamercolorbox}
    \vfill
\end{frame}

\begin{frame}{A naive formulation}
    $w_{ijz}$ is the weight $z$ of neuron $j$ in layer $z$\\
    Gradients of our Error Function: $\nabla E = \{\frac{\partial E}{\partial w_{1}}, \frac{\partial E}{\partial w_{2}}, ..., \frac{\partial E}{\partial w_{l}}\}$
    \vfill
    \pause\begin{mydef}
        update weight: $\Delta w_{ij} = - \lambda \cdot \frac{\partial E}{\partial w_{ij}}$, where $\lambda$ is the learning rate ("step size")
    \end{mydef}
\end{frame}

\begin{frame}{This is expensive!}
    \begin{figure}
        \includegraphics[width=0.8\textwidth]{../assets/mlp_model.png}
    \end{figure}
    \begin{itemize}
        \pause \item $5\cdot3+5*2=25$ weights!
        \pause \item often hundreds of thousands of weights in real scenarios!
        \pause \item and this is \textbf{one} update
    \end{itemize}
\end{frame}

\begin{frame}{Recap: Generalization of the Chain-Rule}
    single variable: $[f \circ g (x)]'= (f' \circ g)(x) \cdot g'(x)$\\
    different notation: for $y = f(t)$, $t = g(x)$: $\frac{d y}{d x} = \frac{d y}{d t}\frac{d t}{d x}$
    \vfill
    generalized to multivar.:\\ For $y = f(m_1,m_2)$,$m_1 = g(x_1,x_2)$ and $m_2 = h(x_1, x_2)$ :\\ $\frac{\partial y}{\partial x_1} = \frac{\partial y}{\partial m_1} \frac{\partial m_1}{\partial x_1} + \frac{\partial y}{\partial m_2} \frac{\partial m_2}{\partial x_1}$
\end{frame}

\begin{frame}{Chain rule to the rescue!}
    $y_{iz} = f(n_{iz})$, $n_{iz} = w_{iz}^T \cdot x_z + b_{iz}$ and trained with $H(\vec{target}, \vec{y_2})$
    \vfill
    \begin{align}
        \frac{\partial H}{\partial w_{piz}} & = \frac{\partial H}{\partial y_{iz}}\frac{\partial y_{iz}}{\partial w_{piz}} \\
        \onslide<2->  {& = \textcolor{blue}{\frac{\partial H}{\partial y_{iz}}\frac{\partial y_{iz}}{\partial n_{iz}}}\frac{\partial n_{iz}}{\partial w_{piz}} \\}
        \onslide<3-> {& =(\sum_{j_{(z +1)} = 0}^{l_{(z+1)}}\frac{\partial H}{\partial y_{j_{(z+1)}(z + 1)}}\frac{\partial y_{j_{(z+1)}(z + 1)}}{\partial y_{iz}})\frac{\partial y_{iz}}{\partial n_{iz}}x_{piz}}
    \end{align}
\end{frame}

\begin{frame}{Chain rule to the rescue!}
    $y_{iz} = f(n_{iz})$, $n_{iz} = w_{iz}^T \cdot x_z + b_{iz}$ and trained with $H(\vec{target}, \vec{y_2})$
    \vfill
    \begin{align}
        \frac{\partial H}{\partial w_{piz}} & =(\sum_{j_{(z +1)} = 0}^{l_{(z+1)}}\frac{\partial H}{\partial y_{j_{(z+1)}(z + 1)}}\frac{\partial y_{j_{(z+1)}(z + 1)}}{\partial y_{iz}})\frac{\partial y_{iz}}{\partial n_{iz}}x_{piz} \\
        \onslide<2-> {& =(\sum_{j_{(z +1)} = 0}^{l_{(z+1)}}\textcolor{blue}{\frac{\partial H}{\partial y_{j_{(z+1)}(z + 1)}}\frac{\partial y_{j_{(z+1)}(z + 1)}}{\partial n_{j_{(z+1)}(z + 1)}}}w_{ij_{(z+1)}(z + 1)})\frac{\partial y_{iz}}{\partial n_{iz}}x_{piz}}
    \end{align}
\end{frame}

\begin{frame}{Chain rule to the rescue!}
    \begin{figure}
        \includegraphics[width=0.8\textwidth]{../assets/mlp_model.png}
    \end{figure}
\end{frame}

\printbibliography

\end{document}